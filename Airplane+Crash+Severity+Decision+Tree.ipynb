{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(r\"F:\\Machine_learning\\HackerEarth\\train.csv\")\n",
    "test = pd.read_csv(r\"F:\\Machine_learning\\HackerEarth\\test.csv\")\n",
    "\n",
    "train.columns\n",
    "train.dtypes\n",
    "# ALL features are either float or integers. and the output is categorical into 4 values. which will be mapped to 1,2,3,4\n",
    "train.Violations.value_counts() # this is categorical Variable\n",
    "train.Accident_Type_Code.value_counts() # This is a Categorical variable\n",
    "\n",
    "\n",
    "train = pd.get_dummies(train, columns =['Accident_Type_Code','Violations'])\n",
    "test = pd.get_dummies(test, columns =['Accident_Type_Code','Violations'])\n",
    "\n",
    "train.columns\n",
    "train = train[['Accident_ID', 'Safety_Score', 'Days_Since_Inspection',\n",
    "       'Total_Safety_Complaints', 'Control_Metric', 'Turbulence_In_gforces',\n",
    "       'Cabin_Temperature', 'Max_Elevation', 'Adverse_Weather_Metric',\n",
    "        'Accident_Type_Code_2',\n",
    "       'Accident_Type_Code_3', 'Accident_Type_Code_4', 'Accident_Type_Code_5',\n",
    "       'Accident_Type_Code_6', 'Accident_Type_Code_7', \n",
    "       'Violations_1', 'Violations_2', 'Violations_3', 'Violations_4',\n",
    "       'Violations_5','Severity']] # 'Accident_Type_Code_1','Violations_0',\n",
    "# 'Severity' is sent to last columns as that is the output. Accident_ID is made first columns since thats the output format.\n",
    "\n",
    "train.Severity.value_counts().sum() # 10000 values\n",
    "train.shape # 10000 x 23\n",
    "# to confirm the values in the output and shape of the train data.\n",
    "train.Severity.value_counts() # Distribution of the data along output types.\n",
    "\n",
    "# Mapping all 4 types to numeric values. \n",
    "train.Severity = train.Severity.map({'Highly_Fatal_And_Damaging':0,\n",
    "                                     'Significant_Damage_And_Serious_Injuries':1,\n",
    "                                     'Minor_Damage_And_Injuries':2,\n",
    "                                     'Significant_Damage_And_Fatalities':3},)\n",
    "test.columns\n",
    "# Adding Accident_ID as the first column to the test data.\n",
    "test = test[['Accident_ID','Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints',\n",
    "       'Control_Metric', 'Turbulence_In_gforces', 'Cabin_Temperature',\n",
    "       'Max_Elevation', 'Adverse_Weather_Metric',\n",
    "        'Accident_Type_Code_2', 'Accident_Type_Code_3',\n",
    "       'Accident_Type_Code_4', 'Accident_Type_Code_5', 'Accident_Type_Code_6',\n",
    "       'Accident_Type_Code_7',  'Violations_1', 'Violations_2',\n",
    "       'Violations_3', 'Violations_4', 'Violations_5']] # 'Accident_Type_Code_1','Violations_0',\n",
    "\n",
    "train.shape, test.shape # one extra column in train data which is the output.\n",
    "# since ID's are not the part of the data input, they are saved into different columns and later will mapped onto\n",
    "# the output data for submission.\n",
    "Acc_ID_Train = train.Accident_ID\n",
    "Acc_ID_Test = test.Accident_ID\n",
    "# Dropping the Accident ID\n",
    "train = train.iloc[:,1:]\n",
    "test = test.iloc[:,1:]\n",
    "\n",
    "\n",
    "# Create X_train, y_train and we have test data withour output.\n",
    "X = train.iloc[:,0:-1]\n",
    "y = train.iloc[:,[-1]] # severityb\n",
    "\n",
    "# X.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X, y &#10132; X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model, metrics \n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "# Fitting Decision Tree Classification to the Training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0,max_depth=85, max_leaf_nodes = 300)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[843,  26,  18,  18],\n",
       "       [ 27, 791,  20,   5],\n",
       "       [ 30,  21, 699,   8],\n",
       "       [ 13,   6,  14, 461]], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9313092928128589"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 100)\n",
    "accuracies.mean()\n",
    "# accuracies.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.13333333333334"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm\n",
    "metrics.accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_sub = classifier.predict(test)\n",
    "\n",
    "y_pred_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sub = pd.DataFrame(Acc_ID_Test)\n",
    "sub['Severity'] = y_pred_sub.tolist()\n",
    "sub.Severity = sub.Severity.map({0:'Highly_Fatal_And_Damaging',\n",
    "                   1:'Significant_Damage_And_Serious_Injuries',\n",
    "                   2:'Minor_Damage_And_Injuries',\n",
    "                   3:'Significant_Damage_And_Fatalities'})\n",
    "sub.to_csv(r\"F:\\Machine_learning\\HackerEarth\\sample_submission_DTR.csv\",index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# X, y as Training Data (No Spliting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model, metrics \n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "# Fitting Decision Tree Classification to the Training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0, max_leaf_nodes = 300) #max_depth=85,\n",
    "classifier.fit(X, y)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2976,   18,   14,   41],\n",
       "       [  18, 2682,   24,    5],\n",
       "       [  32,   10, 2478,    7],\n",
       "       [   7,   11,    1, 1676]], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.11999999999999"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm\n",
    "metrics.accuracy_score(y, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94 (+/- 0.043)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X, y = y, cv = 100)\n",
    "print(\"Accuracy: %0.2f (+/- %0.3f)\" % (accuracies.mean(), accuracies.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021513672803785824"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_sub = classifier.predict(test)\n",
    "\n",
    "\n",
    "sub = pd.DataFrame(Acc_ID_Test)\n",
    "sub['Severity'] = y_pred_sub.tolist()\n",
    "sub.Severity = sub.Severity.map({0:'Highly_Fatal_And_Damaging',\n",
    "                   1:'Significant_Damage_And_Serious_Injuries',\n",
    "                   2:'Minor_Damage_And_Injuries',\n",
    "                   3:'Significant_Damage_And_Fatalities'})\n",
    "sub.to_csv(r\"F:\\Machine_learning\\HackerEarth\\sample_submission_DTR.csv\",index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(np.random.randn(100, 3))\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "train_OL = train[(np.abs(stats.zscore(train)) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7384, 22)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_OL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create X_train, y_train and we have test data withour output.\n",
    "X_OL = train_OL.iloc[:,0:-1]\n",
    "y_OL = train_OL.iloc[:,[-1]] # severityb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[633,  24,  20,  15],\n",
       "       [ 21, 595,  22,  13],\n",
       "       [ 20,  21, 451,  11],\n",
       "       [ 17,   6,  19, 328]], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics \n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_OL, y_OL, test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "# Fitting Decision Tree Classification to the Training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0,max_depth=85, max_leaf_nodes = 300)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.568592057761734"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91 (+/- 0.025)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.3f)\" % (accuracies.mean(), accuracies.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
